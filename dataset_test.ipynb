{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import vaex\n",
    "import dask\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "from src.preprocessing import symmetrize_data, get_micro_adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def extract_features(orderbook_file_path:str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(orderbook_file_path)[['timestamp', 'asks[0].price', 'bids[0].price', 'asks[0].amount', 'bids[0].amount']]\n",
    "                           \n",
    "   # calculate mid price and bidask spread\n",
    "    df['mid_price'] = (df['asks[0].price'] + df['bids[0].price'])/2\n",
    "    df['ba_spread'] = np.round((df['asks[0].price'] - df['bids[0].price']),5)\n",
    "    df['imbalance'] = df['bids[0].amount']/(df['bids[0].amount'] + df['asks[0].amount'])\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']/1000, unit='ms')\n",
    "\n",
    "    # convert timestamp to datetime format\n",
    "    df = df[['timestamp','mid_price', 'ba_spread', 'imbalance']].set_index('timestamp')\n",
    "    \n",
    "    # resample by 1second frequency\n",
    "    df = df.resample('1s').last().ffill()\n",
    "    return df\n",
    "\n",
    "@dask.delayed\n",
    "def extract_quotes(trade_file_path:str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(trade_file_path)[['timestamp', 'ask_price', 'bid_price', 'ask_amount', 'bid_amount']]\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']/1000, unit='ms')\n",
    "    return df.set_index('timestamp')\n",
    "\n",
    "@dask.delayed\n",
    "def extract_trades(trade_file_path:str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(trade_file_path)[['timestamp', 'side', 'price', 'amount']]\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']/1000, unit='ms')\n",
    "    return df.set_index('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/Users/mac/Desktop/Repos/FBD_Project/datasets/'\n",
    "orderbook_list = sorted(glob.glob(DATA_PATH + 'adausdt/orderbook/*.csv.gz'))\n",
    "quote_list = sorted(glob.glob(DATA_PATH + 'btcusdt/quotes/*.csv.gz'))\n",
    "trade_list = sorted(glob.glob(DATA_PATH + 'btcusdt/trades/*.csv.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 5.25 µs\n"
     ]
    }
   ],
   "source": [
    "# process raw data to get features for calculation.\n",
    "%time\n",
    "all_features = [extract_features(path) for path in orderbook_list[:5]] \n",
    "df_feat = dask.compute(all_features)[0]\n",
    "df_feat = pd.concat(df_feat)\n",
    "\n",
    "# symmetrized data\n",
    "df_sig = symmetrize_data(df_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(732856, 6) (125710, 6)\n"
     ]
    }
   ],
   "source": [
    "g1, B = get_micro_adjustment(df_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_adj = g1 + np.linalg.matrix_power(B, 6) @  g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.120014751155482e-05, -5.120014751155481e-05, 0.0001)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tick_size = abs(df_sig.mid_chg.unique()[1])\n",
    "micro_adj.max(), micro_adj.min(), tick_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do \n",
    "- check bidask imblaance and buy and sell volume (pre-trades only)\n",
    "- eth, btc, ada spread distribution\n",
    "- upgrade microprice prediction (bitcoin too much volatility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # process raw data to get features for calculation.\n",
    "# %time\n",
    "# trades = [extract_trades(path) for path in trade_list[:5]] \n",
    "# quotes = [extract_quotes(path) for path in quote_list[:5]] \n",
    "\n",
    "# df_trade = dask.compute(trades)[0]\n",
    "# df_trade = pd.concat(df_trade)\n",
    "\n",
    "# df_quote = dask.compute(quotes)[0]\n",
    "# df_quote = pd.concat(df_quote)\n",
    "\n",
    "# # join trade and quotes\n",
    "# df_tq = pd.merge(df_quote.reset_index(), df_trade.reset_index(),how='outer', on='timestamp')\n",
    "# df_tq = df_tq.set_index('timestamp').sort_index()\n",
    "\n",
    "# df_tq['ba_spread'] = df_tq['ask_price'] - df_tq['bid_price']\n",
    "# df_tq['imbalance'] = df_tq['bid_amount']/(df_tq['bid_amount'] + df_tq['ask_amount'])\n",
    "# df_tq[['ba_spread', 'imbalance']] = df_tq[['ba_spread', 'imbalance']].ffill()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "231aa2985498be18bfd7f8fe95f88a6579a0cb78031a3e6916d9378116cc6cd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
